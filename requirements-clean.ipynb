{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run me first to import and setup everything\n",
    "# meets many of the Must-Have requirements\n",
    "import time\n",
    "import csv  \n",
    "from myapikey import APIkey\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "# Read CSV\n",
    "def open_csv(path_to_csv):\n",
    "    data = []\n",
    "    with open(path_to_csv) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            if row[0] != '':\n",
    "                data.append(row)\n",
    "    return data\n",
    "\n",
    "# Format dataset with classification (up/down)\n",
    "def add_classification(stocks):\n",
    "    new_stocks = []\n",
    "    last_price = stocks[len(stocks) - 1][4]\n",
    "    new_stocks.append(np.insert(stocks[len(stocks) - 1], 5, 1)) # up\n",
    "    for s in reversed(list(range(len(stocks) - 1))):\n",
    "        if (stocks[s][4] - last_price) > 0:\n",
    "            new_stocks.append(np.insert(stocks[s], 5, 1)) # up\n",
    "        else:\n",
    "            new_stocks.append(np.insert(stocks[s], 5, 0)) # down\n",
    "        last_price = stocks[s][4]\n",
    "    return new_stocks\n",
    "\n",
    "# Format dataset with classification (up/down)\n",
    "def split_sample(data):\n",
    "    sample = []\n",
    "    for start in range(0, len(data) - 50, 50):\n",
    "        sample.append(data[start:start+50])\n",
    "    return sample\n",
    "\n",
    "# Format dataset with classification (up/down)\n",
    "def prepare(group_of_stocks):\n",
    "    prepared_data_set = []\n",
    "    for stock in group_of_stocks:\n",
    "        prepared_data_set.append(split_sample(add_classification(stock[0].to_numpy())))\n",
    "    return prepared_data_set\n",
    "\n",
    "# Format dataset with classification (up/down)\n",
    "def prep_part_two(group_of_stocks):\n",
    "    new_set = []\n",
    "    for stock in group_of_stocks:\n",
    "        for collection in stock:\n",
    "            classification = collection[0][5]\n",
    "            training_data = collection[1:]\n",
    "            new_set.append([training_data, classification])\n",
    "    return new_set\n",
    "\n",
    "# Access API\n",
    "def get_daily(stock):\n",
    "    ts = TimeSeries(key=APIkey, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily(symbol=stock, outputsize='full')\n",
    "    return data, meta_data\n",
    "\n",
    "def get_daily_compact(stock):\n",
    "    ts = TimeSeries(key=APIkey, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily(symbol=stock, outputsize='compact') # this returns 100 datapoints\n",
    "    return data\n",
    "\n",
    "# Wait for API (free) access limit\n",
    "def batch_get_daily(stock_list):\n",
    "    print(\"total (\", len(stock_list), \")\")\n",
    "    big_counter = 0\n",
    "    count = 0\n",
    "    data = []\n",
    "    for stock in stock_list:\n",
    "        if count == 5:\n",
    "            time.sleep(65) # 65 seconds just in case the timing on the server or here isn't perfect\n",
    "            count = 0\n",
    "        data.append(get_daily(stock))\n",
    "        big_counter += 1\n",
    "        print(stock, \":\", big_counter, end=\" \")\n",
    "        count += 1\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "#######                           ########\n",
    "#######    WOULD LIKE TO HAVES    ########\n",
    "#######                           ########\n",
    "##########################################\n",
    "\n",
    "print(\"would like to haves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data as CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wait for API (free) access limit\n",
    "\n",
    "# see \"def batch_get_daily(stock_list)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save results of Training\n",
    "# https://www.tensorflow.org/guide/keras#entire_model\n",
    "model.save('verdurouMKI.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 01:08:05.917105 140572645230400 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0713 01:08:05.920909 140572645230400 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fd950f64dd8>\n"
     ]
    }
   ],
   "source": [
    "# Load Results from Previous Training\n",
    "loaded_model = tf.keras.models.load_model('verdurouMKI.h5')\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Scrape HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Must Haves\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "############                  ############\n",
    "############    MUST HAVES    ############\n",
    "############                  ############\n",
    "##########################################\n",
    "\n",
    "print(\"Must Haves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "# see \"def open_csv(path_to_csv)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Access API\n",
    "# see \"def get_daily(stock)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Select stocks based on ticker symbol\n",
    "stock_names = [\"AAOI\", \"AAP\", \"AAPL\", \"ABMD\", \"ABT\", \"ACET\", \"ADIL\", \"AETI\", \"AFL\", \"AKAM\", \"ALGN\", \"ALQA\", \"AMD\", \n",
    "\"AMG\", \"AMRH\", \"AMZN\", \"ANY\", \"APVO\", \"AVGR\", \"AXSM\", \"BAC\", \"BIIB\", \"BLIN\", \"BLK\", \"BLRX\", \"BSQR\", \"BSX\", \"BTAI\", \n",
    "\"CGA\", \"CGC\", \"CLIR\", \"CMCSA\", \"CMG\", \"COP\", \"COTY\", \"COUP\", \"CPSH\", \"CSCO\", \"CTK\", \"CTRV\", \"CVX\", \"D\", \"DIS\", \n",
    "\"DUK\", \"EXC\", \"EYES\", \"FARO\", \"FB\", \"FCEL\", \"FDS\", \"FLKS\", \"FRAN\", \"FTNT\", \"GE\", \"GM\", \"GNMX\", \"GOOGL\", \"HMC\", \"HOV\", \n",
    "\"HSGX\", \"IGLD\", \"INOD\", \"IVZ\", \"JAGX\", \"JNJ\", \"JPM\", \"JT\", \"KEYS\", \"KOSS\", \"LB\", \"LLY\", \"LPTH\", \"M\", \"MDT\", \"MSFT\", \n",
    "\"MYSZ\", \"NDAQ\", \"NEE\", \"NFLX\", \"NKE\", \"NRG\", \"NVDA\", \"NVFY\", \"ORLY\", \"OSS\", \"OXBR\", \"PFE\", \"PIR\", \"PRGO\", \"QBAK\", \n",
    "\"QUIK\", \"RAD\", \"RBCN\",\"RHT\", \"RL\", \"SBUX\", \"SESN\", \"SFUN\", \"SGMA\", \"SMAR\", \"SO\", \"STZ\", \"SYK\", \"T\", \"TNK\", \"TOPS\", \n",
    "\"TRHC\", \"TRIL\", \"TRIP\", \"TRNX\", \"TSLA\", \"TSN\", \"TTWO\", \"TWMC\", \"TWTR\", \"UA\", \"UAA\", \"UPL\", \"USB\", \"UXIN\", \"V\", \n",
    "\"VRSN\", \"VTVT\", \"VZ\", \"WDC\", \"WFC\", \"WFT\", \"WMT\", \"XOM\", \"ZTS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Store Stock information as a data set\n",
    "stock_data = batch_get_daily(stock_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# (Save the stock data)\n",
    "# f = open('store_stocks_OLD_again.pckl', 'wb') # rename and remove '_new' to load it\n",
    "# pickle.dump(stock_data, f)\n",
    "# f.close()\n",
    "\n",
    "# (Load up the saved data)\n",
    "f = open('store_stocks_OLD.pckl', 'rb')\n",
    "stock_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "print(len(stock_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Format dataset with classification (up/down)\n",
    "# see these functions:\n",
    "# \"def add_classification(stocks)\"\n",
    "# \"def split_sample(data)\"\n",
    "# \"def prepare(group_of_stocks)\"\n",
    "# \"def prep_part_two(group_of_stocks)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# results of preparing the stocks\n",
    "prepped_stocks = prepare(stock_data)\n",
    "data_set = prep_part_two(prepped_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# x_train, y_train, x_test, y_test\n",
    "train_data = []\n",
    "train_class = []\n",
    "test_data = []\n",
    "test_class = []\n",
    "\n",
    "np.random.shuffle(data_set)\n",
    "\n",
    "for combo in data_set:\n",
    "    train_data.append(combo[0])\n",
    "    train_class.append(combo[1])\n",
    "\n",
    "test_data = train_data[int(3 * (len(train_data) / 4)):]\n",
    "test_class = train_class[int(3 * (len(train_class) / 4)):]\n",
    "train_data = train_data[:int(3 * (len(train_data) / 4))]\n",
    "train_class = train_class[:int(3 * (len(train_class) / 4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "7281/7281 [==============================] - 3s 404us/sample - loss: 0.6957 - acc: 0.5030\n",
      "Epoch 2/7\n",
      "7281/7281 [==============================] - 3s 366us/sample - loss: 0.6921 - acc: 0.5089\n",
      "Epoch 3/7\n",
      "7281/7281 [==============================] - 3s 369us/sample - loss: 0.6910 - acc: 0.5100\n",
      "Epoch 4/7\n",
      "7281/7281 [==============================] - 3s 370us/sample - loss: 0.6888 - acc: 0.5105\n",
      "Epoch 5/7\n",
      "7281/7281 [==============================] - 3s 362us/sample - loss: 0.6898 - acc: 0.5009\n",
      "Epoch 6/7\n",
      "7281/7281 [==============================] - 3s 362us/sample - loss: 0.6898 - acc: 0.5056\n",
      "Epoch 7/7\n",
      "7281/7281 [==============================] - 3s 377us/sample - loss: 0.6912 - acc: 0.5023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd9048f75c0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3 must-haves in one cell)\n",
    "# Train\n",
    "# Hidden Nodes\n",
    "# Dropout\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(49, 6)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.softmax),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.array(train_data), np.array(train_class), epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2427/2427 [==============================] - 1s 212us/sample - loss: 0.6944 - acc: 0.5208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6944229909064203, 0.52080756]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "model.evaluate(np.array(test_data), np.array(test_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Real Life Prediction\n",
    "chosen_stock = \"AAPL\"\n",
    "rlp_stock = get_daily_compact(chosen_stock)\n",
    "rlp_data = split_sample(add_classification(rlp_stock.to_numpy()))[0]\n",
    "rlp_data = [rlp_data[:49]]\n",
    "\n",
    "prediction = model.predict_classes(np.array(rlp_data), batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL will go up tomorrow\n"
     ]
    }
   ],
   "source": [
    "# Print results of prediction\n",
    "\n",
    "# 1 = tomorrow will be up\n",
    "# 0 = tomorrow will be down\n",
    "\n",
    "if (prediction == 1):\n",
    "    print(chosen_stock + \" will go up tomorrow\")\n",
    "else:\n",
    "    print(chosen_stock + \" will go down tomorrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (verdurous-stock-market-ai)",
   "language": "python",
   "name": "pycharm-6f9556a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}