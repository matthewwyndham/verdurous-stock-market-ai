{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run me first to import and setup everything\n",
    "import time\n",
    "import csv  \n",
    "from myapikey import APIkey\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def add_classification(stocks):\n",
    "    new_stocks = []\n",
    "    last_price = stocks[len(stocks) - 1][4]\n",
    "    new_stocks.append(np.insert(stocks[len(stocks) - 1], 5, 1)) # up\n",
    "    for s in reversed(list(range(len(stocks) - 1))):\n",
    "        if (stocks[s][4] - last_price) > 0:\n",
    "            new_stocks.append(np.insert(stocks[s], 5, 1)) # up\n",
    "        else:\n",
    "            new_stocks.append(np.insert(stocks[s], 5, 0)) # down\n",
    "        last_price = stocks[s][4]\n",
    "    return new_stocks\n",
    "\n",
    "def split_sample(data):\n",
    "    sample = []\n",
    "    for start in range(0, len(data) - 50, 50):\n",
    "        sample.append(data[start:start+50])\n",
    "    return sample\n",
    "\n",
    "def prepare(group_of_stocks):\n",
    "    prepared_data_set = []\n",
    "    for stock in group_of_stocks:\n",
    "        prepared_data_set.append(split_sample(add_classification(stock[0].to_numpy())))\n",
    "    return prepared_data_set\n",
    "\n",
    "def prep_part_two(group_of_stocks):\n",
    "    new_set = []\n",
    "    for stock in group_of_stocks:\n",
    "        for collection in stock:\n",
    "            classification = collection[0][5]\n",
    "            training_data = collection[1:]\n",
    "            new_set.append([training_data, classification])\n",
    "    return new_set\n",
    "\n",
    "# def get_intraday(stock):\n",
    "#     ts = TimeSeries(key=APIkey, output_format='pandas', indexing_type='integer')\n",
    "#     return ts.get_intraday(symbol=stock, interval='1min', outputsize='full')\n",
    "\n",
    "def get_daily(stock):\n",
    "    ts = TimeSeries(key=APIkey, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily(symbol=stock, outputsize='full')\n",
    "    return data, meta_data\n",
    "\n",
    "def open_csv(path_to_csv):\n",
    "    data = []\n",
    "    with open(path_to_csv) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            if row[0] != '':\n",
    "                data.append(row)\n",
    "    return data\n",
    "\n",
    "def batch_get_daily(stock_list):\n",
    "    print(\"total (\", len(stock_list), \")\")\n",
    "    big_counter = 0\n",
    "    count = 0\n",
    "    data = []\n",
    "    for stock in stock_list:\n",
    "        if count == 5:\n",
    "            time.sleep(65) # 65 seconds just in case the timing on the server or here isn't perfect\n",
    "            count = 0\n",
    "        data.append(get_daily(stock))\n",
    "        big_counter += 1\n",
    "        print(stock, \":\", big_counter, end=\" \")\n",
    "        count += 1\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "#######                           ########\n",
    "#######    WOULD LIKE TO HAVES    ########\n",
    "#######                           ########\n",
    "##########################################\n",
    "\n",
    "print(\"would like to haves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data as CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wait for API (free) access limit\n",
    "import time\n",
    "\n",
    "def batch_get_daily(stock_list):\n",
    "    print(\"total (\", len(stock_list), \")\")\n",
    "    big_counter = 0\n",
    "    count = 0\n",
    "    data = []\n",
    "    for stock in stock_list:\n",
    "        if count == 5:\n",
    "            time.sleep(65) # 65 seconds just in case the timing on the server or here isn't perfect\n",
    "            count = 0\n",
    "        try:\n",
    "            data.append(get_daily(stock))\n",
    "            big_counter += 1\n",
    "        except:\n",
    "            print(stock, \" failed \", big_counter, end=\" \")\n",
    "        else:\n",
    "            print(stock, \":\", big_counter, end=\" \")\n",
    "        count += 1\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save results of Training\n",
    "# https://www.tensorflow.org/guide/keras#entire_model\n",
    "model.save('verdurouMKI.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load Results from Previous Training\n",
    "loaded_model = tf.keras.models.load_model('verdurouMKI.h5')\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Scrape HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "############                  ############\n",
    "############    MUST HAVES    ############\n",
    "############                  ############\n",
    "##########################################\n",
    "\n",
    "print(\"Must Haves\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "# This will read in the CSVs that come from the alpha vantage website, where each CSV\n",
    "# is from a separate stock symbol\n",
    "import csv  \n",
    "\n",
    "def open_csv(path_to_csv):\n",
    "    data = []\n",
    "    with open(path_to_csv) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            if row[0] != '':\n",
    "                data.append(row)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Access API\n",
    "from myapikey import APIkey\n",
    "from alpha_vantage.timeseries import TimeSeries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# must provide an api key (they are free from the alpha vantage website\n",
    "# this determines how much data you can get in how much time.\n",
    "def get_intraday(stock):\n",
    "    ts = TimeSeries(key=APIkey, output_format='pandas', indexing_type='integer')\n",
    "    return ts.get_intraday(symbol=stock, interval='1min', outputsize='full')\n",
    "\n",
    "# provide an api key to access the data\n",
    "def get_daily(stock):\n",
    "    ts = TimeSeries(key=APIkey, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily(symbol=stock, outputsize='full')\n",
    "    return data, meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    }
   ],
   "source": [
    "# Select stocks based on ticker symbol\n",
    "stock_names = [\"A\", \"AAL\", \"AAP\", \"AAPEX\", \"AAPH\", \"AAPIX\", \"AAPJ\", \"AAPL\", \"ABBV\", \"ABEV\", \"ACB\", \"ACN\", \"ADBE\", \"ADIL\", \"ADM\", \"ADPT\", \"ADS\", \"AEE\", \"AEP\", \"AES\", \"AETI\", \"AFL\", \"AGNC\", \"AIG\", \"AIV\", \"AIZ\", \"AJG\", \"AKAM\", \"ALB\", \"ALGN\", \"ALK\", \"ALKS\", \"ALL\", \"ALLE\", \"ALLY\", \"ALXN\", \"AMAT\", \"AMCR\", \"AME\", \"AMG\", \"AMGN\", \"AMP\", \"AMRH\", \"AMRN\", \"AMT\", \"AMZN\", \"ANET\", \"ANSS\", \"ANTM\", \"ANY\", \"AON\", \"AOS\", \"APA\", \"APC\", \"APD\", \"APH\", \"APTV\", \"AQST\", \"ARCE\", \"ARE\", \"ARLO\", \"ARNC\", \"ARVN\", \"ATO\", \"ATVI\", \"AUY\", \"AVB\", \"AVGR\", \"AVTR\", \"AVY\", \"AXP\", \"AXSM\", \"AZO\", \"BA\", \"BABA\", \"BAC\", \"BAX\", \"BBY\", \"BEN\", \"BHGE\", \"BKNG\", \"BLL\", \"BLRX\", \"BMY\", \"BRK.B\", \"BSQR\", \"BSX\", \"BTAI\", \"BWA\", \"CAG\", \"CAH\", \"CAT\", \"CB\", \"CBRE\", \"CCI\", \"CDNS\", \"CELG\", \"CERN\", \"CGA\", \"CHRW\", \"CI\", \"CINF\", \"CL\", \"CLIR\", \"CLX\", \"CMA\", \"CMCSA\", \"CME\", \"CMG\", \"CMI\", \"CNC\", \"CNP\", \"COF\", \"COG\", \"COO\", \"COST\", \"COTY\", \"COUP\", \"CPB\", \"CPRI\", \"CPSH\", \"CSX\", \"CTAS\", \"CTK\", \"CTL\", \"CTRV\", \"CTSH\", \"CTVA\", \"CTXS\", \"CVX\", \"CX\", \"CXO\", \"D\", \"DAL\", \"DD\", \"DE\", \"DFS\", \"DHR\", \"DISCA\", \"DISCK\", \"DISH\", \"DLR\", \"DLTR\", \"DRE\", \"DRI\", \"DUK\", \"DVA\", \"DVN\", \"DXC\", \"EA\", \"EBAY\", \"ECA\", \"ECL\", \"ED\", \"EFX\", \"EMN\", \"EMR\", \"EOG\", \"EPD\", \"EQIX\", \"ES\", \"ESS\", \"ET\", \"ETN\", \"ETR\", \"EVRG\", \"EW\", \"EXC\", \"EXPD\", \"F\", \"FANG\", \"FARO\", \"FAST\", \"FB\", \"FBHS\", \"FCX\", \"FDC\", \"FDS\", \"FDX\", \"FE\", \"FFIV\", \"FIS\", \"FITB\", \"FL\", \"FLIR\", \"FLKS\", \"FLS\", \"FLT\", \"FMC\", \"FOX\", \"FOXA\", \"FRAN\", \"FRC\", \"FRT\", \"FTI\", \"FTNT\", \"FTV\", \"GE\", \"GFI\", \"GGB\", \"GILD\", \"GIS\", \"GLW\", \"GM\", \"GNMX\", \"GOLD\", \"GOOG\", \"GOOGL\", \"GPC\", \"GPK\", \"GPS\", \"GRMN\", \"GWW\", \"HAL\", \"HAS\", \"HBAN\", \"HBI\", \"HCA\", \"HCP\", \"HD\", \"HFC\", \"HII\", \"HLT\", \"HMC\", \"HOG\", \"HOV\", \"HP\", \"HPE\", \"HPQ\", \"HSGX\", \"HST\", \"HSY\", \"HUM\", \"IBM\", \"ICE\", \"IDXX\", \"IFF\", \"IGLD\", \"ILMN\", \"INCY\", \"INFO\", \"INFY\", \"INOD\", \"INTC\", \"IP\", \"IPG\", \"IPGP\", \"IR\", \"IRM\", \"ISRG\", \"IT\", \"ITUB\", \"ITW\", \"IVZ\", \"JD\", \"JEC\", \"JEF\", \"JKHY\", \"JNJ\", \"JNPR\", \"JPM\", \"JT\", \"JWN\", \"K\", \"KEY\", \"KEYS\", \"KGC\", \"KHC\", \"KIM\", \"KLAC\", \"KMB\", \"KMI\", \"KMX\", \"KO\", \"KOSS\", \"KR\", \"KSS\", \"KSU\", \"LEG\", \"LEN\", \"LHX\", \"LIN\", \"LKQ\", \"LMT\", \"LNT\", \"LOW\", \"LPTH\", \"LRCX\", \"LUV\", \"LYB\", \"M\", \"MA\", \"MAA\", \"MAC\", \"MAS\", \"MCHP\", \"MCK\", \"MCO\", \"MDLZ\", \"MDT\", \"MET\", \"MHK\", \"MKC\", \"MKTX\", \"MLM\", \"MMC\", \"MMM\", \"MNST\", \"MO\", \"MOS\", \"MPC\", \"MRK\", \"MRVL\", \"MS\", \"MSCI\", \"MTB\", \"MU\", \"MXIM\", \"MYSZ\", \"NBL\", \"NCLH\", \"NDAQ\", \"NEE\", \"NFLX\", \"NI\", \"NIO\", \"NKE\", \"NKTR\", \"NOC\", \"NOK\", \"NOV\", \"NRG\", \"NTAP\", \"NTNX\", \"NUE\", \"NVDA\", \"NVFY\", \"NWL\", \"NWS\", \"NWSA\", \"NYCB\", \"O\", \"OKE\", \"OMC\", \"ORCL\", \"ORLY\", \"OSS\", \"OXBR\", \"OXY\", \"PAYX\", \"PBCT\", \"PDD\", \"PEG\", \"PEP\", \"PFE\", \"PG\", \"PGR\", \"PH\", \"PHM\", \"PIR\", \"PKI\", \"PLAN\", \"PNC\", \"PNR\", \"PPG\", \"PPL\", \"PRGO\", \"PRU\", \"PSA\", \"PSX\", \"PVH\", \"PXD\", \"PYPL\", \"QBAK\", \"QRVO\", \"QUIK\", \"RBCN\", \"RCL\", \"RE\", \"REG\", \"REGN\", \"RHI\", \"RHT\", \"RIG\", \"RL\", \"RMD\", \"ROK\", \"ROKU\", \"ROL\", \"ROP\", \"ROST\", \"S\", \"SAN\", \"SBAC\", \"SBUX\", \"SCHW\", \"SEE\", \"SESN\", \"SFUN\", \"SGMA\", \"SHW\", \"SIRI\", \"SJM\", \"SLB\", \"SLG\", \"SMAR\", \"SNAP\", \"SNPS\", \"SO\", \"SPGI\", \"SRE\", \"STT\", \"STX\", \"STZ\", \"SWK\", \"SWKS\", \"SYK\", \"SYMC\", \"SYY\", \"TAP\", \"TDG\", \"TEL\", \"TEVA\", \"TFX\", \"TGT\", \"TIF\", \"TJX\", \"TME\", \"TMK\", \"TMO\", \"TMUS\", \"TNK\", \"TOPS\", \"TRHC\", \"TRIL\", \"TRIP\", \"TROW\", \"TRQ\", \"TRV\", \"TSLA\", \"TSM\", \"TSN\", \"TSS\", \"TTWO\", \"TWMC\", \"TWTR\", \"TXT\", \"UAA\", \"UAL\", \"UBER\", \"UDR\", \"UHS\", \"ULTA\", \"UNM\", \"UNP\", \"UPL\", \"UPS\", \"URI\", \"USB\", \"V\", \"VALE\", \"VEON\", \"VFC\", \"VIAB\", \"VIPS\", \"VLO\", \"VMC\", \"VRSK\", \"VRTX\", \"VTVT\", \"VZ\", \"WAT\", \"WBA\", \"WCG\", \"WDC\", \"WELL\", \"WFC\", \"WHR\", \"WLTW\", \"WM\", \"WMB\", \"WMT\", \"WPX\", \"WRK\", \"WU\", \"WY\", \"WYNN\", \"XEC\", \"XEL\", \"XLNX\", \"XOM\", \"XRAY\", \"XRX\", \"XYL\", \"YUM\", \"ZBH\", \"ZION\", \"ZNGA\", \"ZTS\"]\n",
    "print(len(stock_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the stock is valid\n",
    "\n",
    "# import requests\n",
    "# import re\n",
    "# import time\n",
    "\n",
    "# target_string = \"{\\\"GlobalQuote\\\":{}}\"\n",
    "# _bad_string = \"{\\\"Note\\\": \\\"Thank you for using Alpha Vantage! Our standard API call frequency is 5 calls per minute and 500 calls per day. Please visit https://www.alphavantage.co/premium/ if you would like to target a higher API call frequency.\\\"}\"\n",
    "# bad_string = re.sub(r\"\\s\", \"\", _bad_string)\n",
    "# count = 0\n",
    "# true_count = 0\n",
    "# true_length = len(stock_names) / 5\n",
    "\n",
    "# for stock in stock_names:\n",
    "#     _result = requests.get(\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=\" + stock + \"&apikey=SSAQZVKJHSN826NT\").text\n",
    "#     result = re.sub(r\"\\s\", \"\", _result)\n",
    "\n",
    "#     if (result == bad_string):\n",
    "#         print(\"overtime\")\n",
    "#         time.sleep(60)\n",
    "#         _result = requests.get(\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=\" + stock + \"&apikey=SSAQZVKJHSN826NT\").text\n",
    "#         result = re.sub(r\"\\s\", \"\", _result)\n",
    "    \n",
    "#     if (result == target_string):\n",
    "#         print(stock, result)\n",
    "    \n",
    "#     count += 1\n",
    "#     if (count == 5):\n",
    "#         count = 0\n",
    "#         true_count += 1\n",
    "#         print(\"progress: \", true_count, \"/\", true_length)\n",
    "#         time.sleep(61)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total ( 499 )\n",
      "A : 1 AAL : 2 AAP : 3 AAPEX : 4 AAPH : 5 AAPIX : 6 AAPJ : 7 AAPL : 8 ABBV : 9 ABEV : 10 ACB : 11 ACN : 12 ADBE : 13 ADIL : 14 ADM : 15 ADPT : 16 ADS : 17 AEE : 18 AEP : 19 AES : 20 AETI : 21 AFL : 22 AGNC : 23 AIG : 24 AIV : 25 AIZ : 26 AJG : 27 AKAM : 28 ALB : 29 ALGN : 30 ALK : 31 ALKS : 32 ALL : 33 ALLE : 34 ALLY : 35 ALXN : 36 AMAT : 37 AMCR : 38 AME : 39 AMG : 40 AMGN : 41 AMP : 42 AMRH : 43 AMRN : 44 AMT : 45 AMZN : 46 ANET : 47 ANSS : 48 ANTM : 49 ANY : 50 AON : 51 AOS : 52 APA : 53 APC : 54 APD : 55 APH : 56 APTV : 57 AQST : 58 ARCE : 59 ARE : 60 ARLO : 61 ARNC : 62 ARVN : 63 ATO : 64 ATVI : 65 AUY : 66 AVB : 67 AVGR : 68 AVTR : 69 AVY : 70 AXP : 71 AXSM : 72 AZO : 73 BA : 74 BABA : 75 BAC : 76 BAX : 77 BBY : 78 BEN : 79 BHGE : 80 BKNG : 81 BLL : 82 BLRX : 83 BMY : 84 BRK.B : 85 BSQR : 86 BSX : 87 BTAI : 88 BWA : 89 CAG : 90 CAH : 91 CAT : 92 CB : 93 CBRE : 94 CCI : 95 CDNS : 96 CELG : 97 CERN : 98 CGA : 99 CHRW : 100 CI : 101 CINF : 102 CL : 103 CLIR : 104 CLX : 105 CMA : 106 CMCSA : 107 CME : 108 CMG : 109 CMI : 110 CNC : 111 CNP : 112 COF : 113 COG : 114 COO : 115 COST : 116 COTY : 117 COUP : 118 CPB : 119 CPRI : 120 CPSH : 121 CSX : 122 CTAS : 123 CTK : 124 CTL : 125 CTRV : 126 CTSH : 127 CTVA : 128 CTXS : 129 CVX : 130 CX : 131 CXO : 132 D : 133 DAL : 134 DD : 135 DE : 136 DFS : 137 DHR : 138 DISCA : 139 DISCK : 140 DISH : 141 DLR : 142 DLTR : 143 DRE : 144 DRI : 145 DUK : 146 DVA : 147 DVN : 148 DXC : 149 EA : 150 EBAY : 151 ECA : 152 ECL : 153 ED : 154 EFX : 155 EMN : 156 EMR : 157 EOG : 158 EPD : 159 EQIX : 160 ES : 161 ESS : 162 ET : 163 ETN : 164 ETR : 165 EVRG : 166 EW : 167 EXC : 168 EXPD : 169 F : 170 FANG : 171 FARO : 172 FAST : 173 FB : 174 FBHS : 175 FCX : 176 FDC : 177 FDS : 178 FDX : 179 FE : 180 FFIV : 181 FIS : 182 FITB : 183 FL : 184 FLIR : 185 FLKS : 186 FLS : 187 FLT : 188 FMC : 189 FOX : 190 FOXA : 191 FRAN : 192 FRC : 193 FRT : 194 FTI : 195 FTNT : 196 FTV : 197 GE : 198 GFI : 199 GGB : 200 GILD : 201 GIS : 202 GLW : 203 GM : 204 GNMX : 205 GOLD : 206 GOOG : 207 GOOGL : 208 GPC : 209 GPK : 210 GPS : 211 GRMN : 212 GWW : 213 HAL : 214 HAS : 215 HBAN : 216 HBI : 217 HCA : 218 HCP : 219 HD : 220 HFC : 221 HII : 222 HLT : 223 HMC : 224 HOG : 225 HOV : 226 HP : 227 HPE : 228 HPQ : 229 HSGX : 230 HST : 231 HSY : 232 HUM : 233 IBM : 234 ICE : 235 IDXX : 236 IFF : 237 IGLD : 238 ILMN : 239 INCY : 240 INFO : 241 INFY : 242 INOD : 243 INTC : 244 IP : 245 IPG : 246 IPGP : 247 IR : 248 IRM : 249 ISRG : 250 IT : 251 ITUB : 252 ITW : 253 IVZ : 254 JD : 255 JEC : 256 JEF : 257 JKHY : 258 JNJ : 259 JNPR : 260 JPM : 261 JT : 262 JWN : 263 K : 264 KEY : 265 KEYS : 266 KGC : 267 KHC : 268 KIM : 269 KLAC : 270 KMB : 271 KMI : 272 KMX : 273 KO : 274 KOSS : 275 KR : 276 KSS : 277 KSU : 278 LEG : 279 LEN : 280 LHX : 281 LIN : 282 LKQ : 283 LMT : 284 LNT : 285 LOW : 286 LPTH : 287 LRCX : 288 LUV : 289 LYB : 290 M : 291 MA : 292 MAA : 293 MAC : 294 MAS : 295 MCHP : 296 MCK : 297 MCO : 298 MDLZ : 299 MDT : 300 MET : 301 MHK : 302 MKC : 303 MKTX : 304 MLM : 305 MMC : 306 MMM : 307 MNST : 308 MO : 309 MOS : 310 MPC : 311 MRK : 312 MRVL : 313 MS : 314 MSCI : 315 MTB : 316 MU : 317 MXIM : 318 MYSZ : 319 NBL : 320 NCLH : 321 NDAQ : 322 NEE : 323 NFLX : 324 NI : 325 NIO : 326 NKE : 327 NKTR : 328 NOC : 329 NOK : 330 NOV : 331 NRG : 332 NTAP : 333 NTNX : 334 NUE : 335 NVDA : 336 NVFY : 337 NWL : 338 NWS : 339 NWSA : 340 NYCB : 341 O : 342 OKE : 343 OMC : 344 ORCL : 345 ORLY : 346 OSS : 347 OXBR : 348 OXY : 349 PAYX : 350 PBCT : 351 PDD : 352 PEG : 353 PEP : 354 PFE : 355 PG : 356 PGR : 357 PH : 358 PHM : 359 PIR : 360 PKI : 361 PLAN : 362 PNC : 363 PNR : 364 PPG : 365 PPL : 366 PRGO : 367 PRU : 368 PSA : 369 PSX : 370 PVH : 371 PXD : 372 PYPL : 373 QBAK : 374 QRVO : 375 QUIK : 376 RBCN : 377 RCL : 378 RE : 379 REG : 380 REGN : 381 RHI : 382 RHT : 383 RIG : 384 RL : 385 RMD : 386 ROK : 387 ROKU : 388 ROL : 389 ROP : 390 ROST : 391 S : 392 SAN : 393 SBAC : 394 SBUX : 395 SCHW : 396 SEE : 397 SESN : 398 SFUN : 399 SGMA : 400 SHW : 401 SIRI : 402 SJM : 403 SLB : 404 SLG : 405 SMAR : 406 SNAP : 407 SNPS : 408 SO : 409 SPGI : 410 SRE : 411 STT : 412 STX : 413 STZ : 414 SWK : 415 SWKS : 416 SYK : 417 SYMC : 418 SYY : 419 TAP : 420 TDG : 421 TEL : 422 TEVA : 423 TFX : 424 TGT : 425 TIF : 426 TJX : 427 TME : 428 TMK : 429 TMO : 430 TMUS : 431 TNK : 432 TOPS : 433 TRHC : 434 TRIL : 435 TRIP : 436 TROW : 437 TRQ : 438 TRV : 439 TSLA : 440 TSM : 441 TSN : 442 TSS : 443 TTWO : 444 TWMC : 445 TWTR : 446 TXT : 447 UAA : 448 UAL : 449 UBER : 450 UDR : 451 UHS : 452 ULTA : 453 UNM : 454 UNP : 455 UPL : 456 UPS : 457 URI : 458 USB : 459 V : 460 VALE : 461 VEON : 462 VFC : 463 VIAB : 464 VIPS : 465 VLO : 466 VMC : 467 VRSK : 468 VRTX : 469 VTVT : 470 VZ : 471 WAT : 472 WBA : 473 WCG : 474 WDC : 475 WELL : 476 WFC : 477 WHR : 478 WLTW : 479 WM : 480 WMB : 481 WMT : 482 WPX : 483 WRK : 484 WU : 485 WY : 486 WYNN : 487 XEC : 488 XEL : 489 XLNX : 490 XOM : 491 XRAY : 492 XRX : 493 XYL : 494 YUM : 495 ZBH : 496 ZION : 497 ZNGA : 498 ZTS : 499 "
     ]
    }
   ],
   "source": [
    "# Store Stock information as a data set\n",
    "stock_data = batch_get_daily(stock_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(stock_data[0][0])\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('store_stocks_new.pckl', 'wb') # rename and remove '_new' to load it\n",
    "pickle.dump(stock_data, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('store_stocks.pckl', 'rb')\n",
    "stock_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "print(len(stock_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Format dataset with classification (up/down)\n",
    "import numpy as np\n",
    "\n",
    "def add_classification(stocks):\n",
    "    # up = 1, down = 0\n",
    "    new_stocks = []\n",
    "    # column 4 is the end of day price\n",
    "    last_price = stocks[len(stocks) - 1][4]\n",
    "    # the very last price will always be up. Perhaps\n",
    "    # this makes my AI optimistic?\n",
    "    new_stocks.append(np.insert(stocks[len(stocks) - 1], 5, 1)) # up\n",
    "    for s in reversed(list(range(len(stocks) - 1))):\n",
    "        if (stocks[s][4] - last_price) > 0:\n",
    "            new_stocks.append(np.insert(stocks[s], 5, 1)) # up\n",
    "        else:\n",
    "            new_stocks.append(np.insert(stocks[s], 5, 0)) # down\n",
    "        last_price = stocks[s][4]\n",
    "    return new_stocks\n",
    "\n",
    "# accepts an array of all data from one stock\n",
    "# produces chunks to be made into tensors\n",
    "# run this once on each stock and save the resulting array (of arrays)\n",
    "def split_sample(data):\n",
    "    sample = []\n",
    "    for start in range(0, len(data) - 50, 50):\n",
    "        sample.append(data[start:start+50])\n",
    "    return sample\n",
    "\n",
    "# takes the results of batch_get_daily and prepares everything\n",
    "def prepare(group_of_stocks):\n",
    "    prepared_data_set = []\n",
    "    for stock in group_of_stocks:\n",
    "        prepared_data_set.append(split_sample(add_classification(stock[0].to_numpy())))\n",
    "    return prepared_data_set\n",
    "\n",
    "def prep_part_two(group_of_stocks):\n",
    "    new_set = []\n",
    "    for stock in group_of_stocks:\n",
    "        for collection in stock:\n",
    "            classification = collection[0][5]\n",
    "            training_data = collection[1:]\n",
    "            new_set.append([training_data, classification])\n",
    "    return new_set\n",
    "\n",
    "# prepped_stock[n][m][0][5] = the classification!\n",
    "# prepped_stock[n][m][X > 0] = the data sets!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# an example of how to use this data and functions\n",
    "# print(split_sample(add_classification(stock_data[0][0].to_numpy()))[0])\n",
    "\n",
    "# results of preparing the stocks\n",
    "prepped_stocks = prepare(stock_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pickle the prepped stocks!\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('store_prepped_stocks_new.pckl', 'wb') # rename and remove '_new' to load it\n",
    "pickle.dump(prepped_stocks, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('store_prepped_stocks.pckl', 'rb')\n",
    "prepped_stocks = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "print(len(prepped_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# prepped stocks part 2\n",
    "data_set = prep_part_two(prepped_stocks)\n",
    "\n",
    "# now the data should be one array filled with pairs of 49 days worth of \n",
    "# data with the classification of the next day.\n",
    "\n",
    "# TODO: so I need to split this into x_train, y_train and x_test, y_test\n",
    "\n",
    "print(len(data_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save my work\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('store_data_set_new.pckl', 'wb') # rename and remove '_new' to load it\n",
    "pickle.dump(data_set, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('store_data_set.pckl', 'rb')\n",
    "data_set = pickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# x_train, y_train, x_test, y_test\n",
    "train_data = []\n",
    "train_class = []\n",
    "test_data = []\n",
    "test_class = []\n",
    "\n",
    "np.random.shuffle(data_set)\n",
    "\n",
    "# print(data_set[:4])\n",
    "\n",
    "for combo in data_set:\n",
    "    train_data.append(combo[0])\n",
    "    train_class.append(combo[1])\n",
    "\n",
    "test_data = train_data[7707:9707]\n",
    "test_class = train_class[7707:9707]\n",
    "train_data = train_data[0:7706]\n",
    "train_class = train_class[0:7706]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save my work\n",
    "import pickle\n",
    "# train_data = []\n",
    "# train_class = []\n",
    "# test_data = []\n",
    "# test_class = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('store_train_data_new.pckl', 'wb') # rename and remove '_new' to load it\n",
    "pickle.dump(train_data, f)\n",
    "f.close()\n",
    "\n",
    "f = open('store_train_class_new.pckl', 'wb') # rename and remove '_new' to load it\n",
    "pickle.dump(train_class, f)\n",
    "f.close()\n",
    "\n",
    "f = open('store_test_data_new.pckl', 'wb') # rename and remove '_new' to load it\n",
    "pickle.dump(test_data, f)\n",
    "f.close()\n",
    "\n",
    "f = open('store_test_class_new.pckl', 'wb') # rename and remove '_new' to load it\n",
    "pickle.dump(test_class, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open('store_train_data.pckl', 'rb')\n",
    "train_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('store_train_class.pckl', 'rb')\n",
    "train_class = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('store_test_data.pckl', 'rb')\n",
    "test_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('store_test_class.pckl', 'rb')\n",
    "test_class = pickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (3 must-haves in one cell)\n",
    "# Train\n",
    "# Hidden Nodes\n",
    "# Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "# example training\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(49, 6)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.softmax),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.array(train_data), np.array(train_class), epochs=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "model.evaluate(np.array(test_data), np.array(test_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Real Life Prediction\n",
    "def get_daily_compact(stock):\n",
    "    ts = TimeSeries(key=APIkey, output_format='pandas')\n",
    "    data, meta_data = ts.get_daily(symbol=stock, outputsize='compact') # this returns 100 datapoints\n",
    "    return data\n",
    "\n",
    "chosen_stock = \"AAPL\"\n",
    "rlp_stock = get_daily_compact(chosen_stock)\n",
    "rlp_data = split_sample(add_classification(rlp_stock.to_numpy()))[0]\n",
    "rlp_data = [rlp_data[:49]]\n",
    "\n",
    "prediction = model.predict_classes(np.array(rlp_data), batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print results of prediction\n",
    "\n",
    "# 1 = tomorrow will be up\n",
    "# 0 = tomorrow will be down\n",
    "\n",
    "if (prediction == 1):\n",
    "    print(chosen_stock + \" will go up tomorrow\")\n",
    "else:\n",
    "    print(chosen_stock + \" will go down tomorrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (verdurous-stock-market-ai)",
   "language": "python",
   "name": "pycharm-6f9556a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
